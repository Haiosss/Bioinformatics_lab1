{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "PMm45izNRcdk"
      },
      "outputs": [],
      "source": [
        "!pip install biopython\n",
        "!pip install scipy\n",
        "!pip install numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "hNPwBOWmRAIV"
      },
      "outputs": [],
      "source": [
        "from Bio import SeqIO\n",
        "from Bio.Seq import Seq\n",
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "from scipy.spatial.distance import pdist, squareform\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Failu nuskaitymas\n",
        "file_paths = [\n",
        "    \"/content/data/mamalian1.fasta\", \"/content/data/mamalian2.fasta\",\n",
        "    \"/content/data/mamalian3.fasta\", \"/content/data/mamalian4.fasta\",\n",
        "    \"/content/data/bacterial1.fasta\", \"/content/data/bacterial2.fasta\",\n",
        "    \"/content/data/bacterial3.fasta\", \"/content/data/bacterial4.fasta\"\n",
        "]\n",
        "\n",
        "sequences = []\n",
        "labels = []\n",
        "\n",
        "for file_path in file_paths:\n",
        "    with open(file_path, \"r\") as file:\n",
        "        for record in SeqIO.parse(file, \"fasta\"):\n",
        "            sequences.append(record)\n",
        "            labels.append(os.path.splitext(os.path.basename(file_path))[0])"
      ],
      "metadata": {
        "id": "oH8pFMIjod-A"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sudaroma po 6 skaitymo remelius kiekvienai sekai (3 į priekį ir 3 reverse komplementarumo)\n",
        "# Visos remeliu sekos sujungiamos 5 viena concatenated_frames eilute\n",
        "def get_concatenated_reading_frames(sequence):\n",
        "\n",
        "    seq = str(sequence.seq)\n",
        "    rev_seq = str(sequence.reverse_complement().seq)\n",
        "\n",
        "    frames = [seq, seq[1:], seq[2:]]\n",
        "\n",
        "    frames += [rev_seq, rev_seq[1:], rev_seq[2:]]\n",
        "\n",
        "    concatenated_frames = \"\".join(frames)\n",
        "    return concatenated_frames\n",
        "\n",
        "concatenated_sequences = [get_concatenated_reading_frames(seq_record) for seq_record in sequences]"
      ],
      "metadata": {
        "id": "UQuSSC-uom_M"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_codon = \"ATG\"\n",
        "stop_codons = [\"TAA\", \"TAG\", \"TGA\"]\n",
        "\n",
        "# Funkcija suranda ORF'us tarp start ir stop kodonu\n",
        "# Tikrinama, ar tarp start ir stop kodono nera tarpiniu stop kodonu\n",
        "# ORF sekos turi buti ilgesnes nei 100 bp, kad butu pridetos prie rezultatu\n",
        "# ORF pozicijos tikrinamos nuo toliausiai esancio start kodono iki artimiausio stop kodono\n",
        "# Surastos sekos sujungiamos i viena concatenated_orfs eilute\n",
        "def find_and_concatenate_orfs(seq):\n",
        "    orfs = []\n",
        "    start_positions = []\n",
        "\n",
        "    for i in range(0, len(seq) - 2, 3):\n",
        "        codon = seq[i:i+3]\n",
        "\n",
        "        if codon == start_codon:\n",
        "            start_positions.append(i)\n",
        "\n",
        "        elif codon in stop_codons:\n",
        "            if start_positions:\n",
        "                for start in reversed(start_positions):\n",
        "                    orf = seq[start:i+3]\n",
        "\n",
        "                    intermediate_seq = seq[start:i]\n",
        "                    if not any(intermediate_seq[j:j+3] in stop_codons for j in range(0, len(intermediate_seq), 3)):\n",
        "                        if len(orf) >= 100:\n",
        "                            orfs.append(orf)\n",
        "\n",
        "                        start_positions = []\n",
        "                        break\n",
        "\n",
        "    concatenated_orfs = \"\".join(orfs)\n",
        "    return concatenated_orfs\n",
        "\n",
        "concatenated_orfs_per_sequence = [find_and_concatenate_orfs(seq) for seq in concatenated_sequences]"
      ],
      "metadata": {
        "id": "Rm-QrFIDSl4n"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Funkcija vercia ORF sekas i baltymo sekas, naudodama Biopython translate metoda\n",
        "# Vertimas sustoja ties pirmu stop kodonu (to_stop=True)\n",
        "# Gautos baltymo sekos saugomos protein_seqs sarase\n",
        "def translate_concatenated_orfs(concatenated_orfs_list):\n",
        "    protein_seqs = []\n",
        "    for concatenated_orf in concatenated_orfs_list:\n",
        "        coding_dna = Seq(concatenated_orf)\n",
        "        protein_seq = coding_dna.translate(to_stop=True)\n",
        "        protein_seqs.append(str(protein_seq))\n",
        "    return protein_seqs\n",
        "\n",
        "protein_sequences = translate_concatenated_orfs(concatenated_orfs_per_sequence)"
      ],
      "metadata": {
        "id": "s5-QY4Y_zoEz"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "from collections import defaultdict\n",
        "\n",
        "# Visi galimi aminorugsciu kodonai\n",
        "amino_acids = \"ACDEFGHIKLMNPQRSTVWY\"\n",
        "\n",
        "# Sudaromi visi galimi kodonai (po viena aminorugsti) ir dikodonai (aminorugsciu poros)\n",
        "all_codons = list(amino_acids)\n",
        "all_dicodons = [\"\".join(pair) for pair in itertools.product(amino_acids, repeat=2)]\n",
        "\n",
        "def codon_frequency(protein_sequences):\n",
        "    codon_freq_list = []\n",
        "    dicodon_freq_list = []\n",
        "\n",
        "# Inicializuojami kodonu ir dikodonu skaiciavimo zodynai\n",
        "    for protein in protein_sequences:\n",
        "        codon_counts = defaultdict(int, {codon: 0 for codon in all_codons})\n",
        "        dicodon_counts = defaultdict(int, {dicodon: 0 for dicodon in all_dicodons})\n",
        "\n",
        "# Kiekvieno kodono (aminorugsties) skaiciavimas baltymo sekoje\n",
        "        for i in range(len(protein)):\n",
        "            codon = protein[i]\n",
        "            codon_counts[codon] += 1\n",
        "\n",
        "# Kiekvieno dikodono (aminorugsciu poros) skaiciavimas baltymo sekoje\n",
        "        for i in range(len(protein) - 1):\n",
        "            dicodon = protein[i:i+2]\n",
        "            dicodon_counts[dicodon] += 1\n",
        "\n",
        "# Rezultatai pridedami prie kodonu ir dikodonu dazniu sarasu\n",
        "        codon_freq_list.append(codon_counts)\n",
        "        dicodon_freq_list.append(dicodon_counts)\n",
        "\n",
        "    return codon_freq_list, dicodon_freq_list\n",
        "\n",
        "codon_freq_list, dicodon_freq_list = codon_frequency(protein_sequences)"
      ],
      "metadata": {
        "id": "-lJ84N5iZD72"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Funkcija normalizuoja kodonu ir dikodonu daznius pagal sekos ilgi\n",
        "def normalize_frequencies(frequencies_list, total_lengths):\n",
        "    normalized_list = []\n",
        "    for i, frequencies in enumerate(frequencies_list):\n",
        "        normalized_frequencies = defaultdict(int)\n",
        "# Normalizuojamas kiekvieno kodono daznis padalinant is sekos ilgio\n",
        "        for codon, count in frequencies.items():\n",
        "            normalized_frequencies[codon] = count / total_lengths[i]\n",
        "        normalized_list.append(normalized_frequencies)\n",
        "    return normalized_list\n",
        "\n",
        "# Skaiciuojamas kiekvienos baltymo sekos ilgis\n",
        "sequence_lengths = [len(seq) for seq in protein_sequences]\n",
        "\n",
        "# Normalizuojami kodonu ir dikodonu dazniai pagal sekos ilgi\n",
        "codon_freq_list = normalize_frequencies(codon_freq_list, sequence_lengths)\n",
        "dicodon_freq_list = normalize_frequencies(dicodon_freq_list, sequence_lengths)"
      ],
      "metadata": {
        "id": "wDOTOL-0z_HE"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "\n",
        "amino_acids = \"ACDEFGHIKLMNPQRSTVWY\"\n",
        "all_codons = list(amino_acids)\n",
        "all_dicodons = [\"\".join(pair) for pair in itertools.product(amino_acids, repeat=2)]\n",
        "\n",
        "#Funkcija pavercia dazniu zodyna i vektoriu su kodonais ar dikodonais. Jei daznio nera, priskiriama 0 reiksme.\n",
        "def freq_dict_to_vector(freq_dict, all_items):\n",
        "    vector = [freq_dict.get(item, 0) for item in all_items]\n",
        "    return vector\n",
        "\n",
        "# Dazniu zodynai verciami i vektorius visoms sekos kombinacijoms\n",
        "codon_freq_vectors = [freq_dict_to_vector(freq, all_codons) for freq in codon_freq_list]\n",
        "dicodon_freq_vectors = [freq_dict_to_vector(freq, all_dicodons) for freq in dicodon_freq_list]\n",
        "\n",
        "# Apskaiciuoja atstumo matrica tarp visu seku, naudodama dazniu vektorius.\n",
        "def calculate_distance_matrix(vectors):\n",
        "    dist_matrix = squareform(pdist(vectors, metric=\"euclidean\"))\n",
        "    return dist_matrix\n",
        "\n",
        "codon_dist_matrix = calculate_distance_matrix(codon_freq_vectors)\n",
        "dicodon_dist_matrix = calculate_distance_matrix(dicodon_freq_vectors)"
      ],
      "metadata": {
        "id": "EYwNdoc04BEf"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Funkcija suformatuoja matrica i Phylip formata\n",
        "def format_phylip_matrix(matrix, labels):\n",
        "    n = len(matrix)\n",
        "    result = [f\"{n}\"]\n",
        "    for i, row in enumerate(matrix):\n",
        "        row_str = \" \".join([f\"{dist:.3f}\" for dist in row])\n",
        "        result.append(f\"{labels[i]} {row_str}\")\n",
        "    return \"\\n\".join(result)\n",
        "\n",
        "# Dikodonu atstumu matrica suformatuojama i Phylip formata\n",
        "phylip_dicodon_matrix = format_phylip_matrix(dicodon_dist_matrix, labels)\n",
        "print(\"Dikodonu matrica:\")\n",
        "print(phylip_dicodon_matrix)\n",
        "\n",
        "# Kodonu atstumu matrica suformatuojama i Phylip formata\n",
        "phylip_codon_matrix = format_phylip_matrix(codon_dist_matrix, labels)\n",
        "print(\"\\nKodonu matrica:\")\n",
        "print(phylip_codon_matrix)\n",
        "\n",
        "# Matricos irasomos i failus\n",
        "with open(\"/content/codon_distance_matrix.phylip\", \"w\") as f:\n",
        "    f.write(phylip_codon_matrix)\n",
        "\n",
        "with open(\"/content/dicodon_distance_matrix.phylip\", \"w\") as f:\n",
        "    f.write(phylip_dicodon_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySc0OUeP0e96",
        "outputId": "90a1160c-849f-42ad-a23e-7fe7acf66dfa"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dikodonu matrica:\n",
            "8\n",
            "mamalian1 0.000 0.172 0.165 0.185 0.198 0.175 0.201 0.168\n",
            "mamalian2 0.172 0.000 0.169 0.168 0.186 0.172 0.202 0.162\n",
            "mamalian3 0.165 0.169 0.000 0.190 0.193 0.175 0.214 0.163\n",
            "mamalian4 0.185 0.168 0.190 0.000 0.189 0.179 0.205 0.167\n",
            "bacterial1 0.198 0.186 0.193 0.189 0.000 0.174 0.181 0.159\n",
            "bacterial2 0.175 0.172 0.175 0.179 0.174 0.000 0.194 0.137\n",
            "bacterial3 0.201 0.202 0.214 0.205 0.181 0.194 0.000 0.181\n",
            "bacterial4 0.168 0.162 0.163 0.167 0.159 0.137 0.181 0.000\n",
            "\n",
            "Kodonu matrica:\n",
            "8\n",
            "mamalian1 0.000 0.247 0.190 0.310 0.264 0.230 0.307 0.214\n",
            "mamalian2 0.247 0.000 0.197 0.183 0.199 0.182 0.250 0.172\n",
            "mamalian3 0.190 0.197 0.000 0.263 0.246 0.222 0.303 0.186\n",
            "mamalian4 0.310 0.183 0.263 0.000 0.248 0.259 0.308 0.231\n",
            "bacterial1 0.264 0.199 0.246 0.248 0.000 0.131 0.144 0.136\n",
            "bacterial2 0.230 0.182 0.222 0.259 0.131 0.000 0.205 0.105\n",
            "bacterial3 0.307 0.250 0.303 0.308 0.144 0.205 0.000 0.215\n",
            "bacterial4 0.214 0.172 0.186 0.231 0.136 0.105 0.215 0.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "\n",
        "amino_acids = \"ACDEFGHIKLMNPQRSTVWY\"\n",
        "\n",
        "codon_name_map = {\n",
        "    \"A\": \"Alanine\", \"C\": \"Cysteine\", \"D\": \"Aspartic acid\", \"E\": \"Glutamic acid\",\n",
        "    \"F\": \"Phenylalanine\", \"G\": \"Glycine\", \"H\": \"Histidine\", \"I\": \"Isoleucine\",\n",
        "    \"K\": \"Lysine\", \"L\": \"Leucine\", \"M\": \"Methionine\", \"N\": \"Asparagine\",\n",
        "    \"P\": \"Proline\", \"Q\": \"Glutamine\", \"R\": \"Arginine\", \"S\": \"Serine\",\n",
        "    \"T\": \"Threonine\", \"V\": \"Valine\", \"W\": \"Tryptophan\", \"Y\": \"Tyrosine\"\n",
        "}\n",
        "\n",
        "all_codons = list(amino_acids)\n",
        "\n",
        "all_dicodons = [\"\".join(pair) for pair in itertools.product(amino_acids, repeat=2)]\n",
        "\n",
        "# Funkcija grazina pilna dikodono pavadinima\n",
        "def dicodon_name(dicodon):\n",
        "    return f\"{codon_name_map[dicodon[0]]}-{codon_name_map[dicodon[1]]}\"\n",
        "\n",
        "# Funkcija skaiciuoja kodonu arba dikodonu dazniu variacija\n",
        "def calculate_variance(frequency_list, all_items):\n",
        "    variances = defaultdict(float)\n",
        "\n",
        "    for item in all_items:\n",
        "        frequencies = [freq_dict.get(item, 0) for freq_dict in frequency_list]\n",
        "        variances[item] = np.var(frequencies)\n",
        "    return variances\n",
        "\n",
        "codon_variances = calculate_variance(codon_freq_list, all_codons)\n",
        "dicodon_variances = calculate_variance(dicodon_freq_list, all_dicodons)\n",
        "\n",
        "# Kodonu ir dikodonu variacijos rusiuojamos didejimo tvarka\n",
        "sorted_codon_variances = sorted(codon_variances.items(), key=lambda x: x[1], reverse=True)\n",
        "sorted_dicodon_variances = sorted(dicodon_variances.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "print(\"Top 3 labiausiai varuijuojantis kodonai:\")\n",
        "for codon, variance in sorted_codon_variances[:3]:\n",
        "    full_name = codon_name_map[codon]\n",
        "    print(f\"{codon} ({full_name}): Variance = {variance:.6f}\")\n",
        "\n",
        "print(\"\\nTop 3 labiausiai varuijuojantis dikodonai:\")\n",
        "for dicodon, variance in sorted_dicodon_variances[:3]:\n",
        "    full_names = dicodon_name(dicodon)\n",
        "    print(f\"{dicodon} ({full_names}): Variance = {variance:.6f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ho7oX_GZZv_l",
        "outputId": "daf95788-fb05-4959-b07c-f6161c2d1b4f"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 3 labiausiai varuijuojantis kodonai:\n",
            "E (Glutamic acid): Variance = 0.003413\n",
            "R (Arginine): Variance = 0.003267\n",
            "K (Lysine): Variance = 0.002589\n",
            "\n",
            "Top 3 labiausiai varuijuojantis dikodonai:\n",
            "EL (Glutamic acid-Leucine): Variance = 0.000366\n",
            "IE (Isoleucine-Glutamic acid): Variance = 0.000366\n",
            "TE (Threonine-Glutamic acid): Variance = 0.000263\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}